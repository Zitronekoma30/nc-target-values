@report{FHWA,
  author       = {Federal Highway Administration},
  title        = {LTPP Computed Parameter: Dynamic Modulus},
  url = {https://www.fhwa.dot.gov/publications/research/infrastructure/pavements/ltpp/10035/005.cfm},
  year = {2011},
  mont = sep,
}

@misc{Hyperplane,
  author       = {DeepAI},
  title        = {Hyperplane},
  url = {https://images.deepai.org/glossary-terms/3bb86574825445cba73a67222b744648/hyperplane.png},
  note = "Last accessed: 2025-07-10"
}

@techreport{begic,
  author    = {Jasmin Begic and Christoph Kuehleitner and Philipp Moser},
  title     = {Neural Networks with Continuously Adjusting Target Values},
  institution = {University of Salzburg, Department of Artificial Intelligence and Human Interfaces},
  year      = {2023},
  month     = jul,
}

@techreport{almasov,
  author      = {Deni Almasov-Misaev and Rupert Haderer and Elnes Kovacevic},
  title       = {An Analysis of Sigma Adaptation of Target Values in ANN Training},
  institution = {University of Salzburg, Department of Artificial Intelligence and Human Interfaces},
  year        = {2024},
  month       = sep,
  note        = {Project report supervised by Helmut Mayer},
}



@article{krothapalli_adaptive_2020,
  title     = {Adaptive Label Smoothing},
  author    = {Krothapalli, Ujwal and Abbott, A. Lynn},
  journal   = {arXiv preprint arXiv:2009.06432},
  year      = {2020},
  url       = {https://arxiv.org/abs/2009.06432},
  doi       = {10.48550/arXiv.2009.06432}
}


@article{dos_santos_rethinking_2024,
	title = {Rethinking {Regularization} with {Random} {Label} {Smoothing}},
	volume = {56},
	issn = {1573-773X},
	url = {https://link.springer.com/10.1007/s11063-024-11579-z},
	doi = {10.1007/s11063-024-11579-z},
	abstract = {Abstract
            Regularization helps to improve machine learning techniques by penalizing the models during training. Such approaches act in either the input, internal, or output layers. Regarding the latter, label smoothing is widely used to introduce noise in the label vector, making learning more challenging. This work proposes a new label regularization method, Random Label Smoothing, that attributes random values to the labels while preserving their semantics during training. The idea is to change the entire label into fixed arbitrary values. Results show improvements in image classification and super-resolution tasks, outperforming state-of-the-art techniques for such purposes.},
	language = {en},
	number = {3},
	urldate = {2025-07-04},
	journal = {Neural Processing Letters},
	author = {Dos Santos, Claudio Filipi Gonçalves and Papa, João Paulo},
	month = apr,
	year = {2024},
	pages = {157},
}

@misc{pracsec_pe_2021,
	title = {{PE} {Malware} {Machine} {Learning} {Dataset}},
	url = {https://practicalsecurityanalytics.com/pe-malware-machine-learning-dataset/},
	abstract = {The purpose of this dataset is to provide raw labeled portable executables to security and AI researchers in order to improve cyber security in the industry. Many of the datasets that I have seen (…},
	language = {en-US},
	urldate = {2025-07-02},
	journal = {Practical Security Analytics LLC},
	author = {{pracsec}},
	month = jun,
	year = {2021},
}

@article{noauthor_notitle_nodate,
}

@inproceedings{jordaney_transcend_2017,
	address = {Vancouver, BC},
	title = {Transcend: {Detecting} {Concept} {Drift} in {Malware} {Classification} {Models}},
	isbn = {978-1-931971-40-9},
	shorttitle = {Transcend},
	url = {https://www.usenix.org/conference/usenixsecurity17/technical-sessions/presentation/jordaney},
	language = {en},
	urldate = {2025-07-02},
	publisher = {USENIX Association},
	author = {Jordaney, Roberto and Sharad, Kumar and Dash, Santanu K. and Wang, Zhi and Papini, Davide and Nouretdinov, Ilia and Cavallaro, Lorenzo},
	year = {2017},
	pages = {625--642},
}

@inproceedings{pant_image-based_2021,
	address = {Sanya China},
	title = {Image-based {Malware} {Classification} using {Deep} {Convolutional} {Neural} {Network} and {Transfer} {Learning}},
	isbn = {978-1-4503-8586-2},
	url = {https://dl.acm.org/doi/10.1145/3503047.3503081},
	doi = {10.1145/3503047.3503081},
	language = {en},
	urldate = {2025-07-02},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Advanced} {Information} {Science} and {System}},
	publisher = {ACM},
	author = {Pant, Dipendra and Bista, Rabindra},
	month = nov,
	year = {2021},
	pages = {1--6},
}

@inproceedings{nataraj_malware_2011,
	address = {Pittsburgh Pennsylvania USA},
	title = {Malware images: visualization and automatic classification},
	isbn = {978-1-4503-0679-9},
	shorttitle = {Malware images},
	url = {https://dl.acm.org/doi/10.1145/2016904.2016908},
	doi = {10.1145/2016904.2016908},
	language = {en},
	urldate = {2025-07-02},
	booktitle = {Proceedings of the 8th {International} {Symposium} on {Visualization} for {Cyber} {Security}},
	publisher = {ACM},
	author = {Nataraj, L. and Karthikeyan, S. and Jacob, G. and Manjunath, B. S.},
	month = jul,
	year = {2011},
	pages = {1--7},
}

@inproceedings{yang_bodmas_2021,
	address = {San Francisco, CA, USA},
	title = {{BODMAS}: {An} {Open} {Dataset} for {Learning} based {Temporal} {Analysis} of {PE} {Malware}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-6654-3732-5},
	shorttitle = {{BODMAS}},
	url = {https://ieeexplore.ieee.org/document/9474321/},
	doi = {10.1109/SPW53761.2021.00020},
	urldate = {2025-07-02},
	booktitle = {2021 {IEEE} {Security} and {Privacy} {Workshops} ({SPW})},
	publisher = {IEEE},
	author = {Yang, Limin and Ciptadi, Arridhana and Laziuk, Ihar and Ahmadzadeh, Ali and Wang, Gang},
	month = may,
	year = {2021},
	pages = {78--84},
}

@misc{harang_sorel-20m_2020,
	title = {{SOREL}-{20M}: {A} {Large} {Scale} {Benchmark} {Dataset} for {Malicious} {PE} {Detection}},
	shorttitle = {{SOREL}-{20M}},
	url = {http://arxiv.org/abs/2012.07634},
	doi = {10.48550/arXiv.2012.07634},
	abstract = {In this paper we describe the SOREL-20M (Sophos/ReversingLabs-20 Million) dataset: a large-scale dataset consisting of nearly 20 million files with pre-extracted features and metadata, high-quality labels derived from multiple sources, information about vendor detections of the malware samples at the time of collection, and additional ``tags'' related to each malware sample to serve as additional targets. In addition to features and metadata, we also provide approximately 10 million ``disarmed'' malware samples -- samples with both the optional{\textbackslash}\_headers.subsystem and file{\textbackslash}\_header.machine flags set to zero -- that may be used for further exploration of features and detection strategies. We also provide Python code to interact with the data and features, as well as baseline neural network and gradient boosted decision tree models and their results, with full training and evaluation code, to serve as a starting point for further experimentation.},
	urldate = {2025-07-02},
	publisher = {arXiv},
	author = {Harang, Richard and Rudd, Ethan M.},
	month = dec,
	year = {2020},
	note = {arXiv:2012.07634 [cs]},
	keywords = {Computer Science - Cryptography and Security},
}
